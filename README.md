# ğŸ“˜ Neurocore
### *A lightweight neural-state engine for Rust â€” created by **Seleste Waithaka**.*



## ğŸš€ Overview

**Neurocore** is a fast, lightweight, and extendable neural-state processing engine written in Rust.  
It provides simple building blocks for creating neural layers, activation functions, and forward-propagation logic â€” all without heavy machine-learning dependencies.

This crate focuses on **speed**, **minimalism**, and **clean architecture**, giving developers a flexible foundation for experimenting with neural computation in pure Rust.



## âœ¨ Features

- ğŸ”¹ Fully modular neural layers (Dense layers)
- ğŸ”¹ Built-in activation functions (ReLU, Sigmoid, Tanh, Linear)
- ğŸ”¹ Forward propagation engine
- ğŸ”¹ Serde serialization + deserialization
- ğŸ”¹ Safe, fast, 100% Rust implementation
- ğŸ”¹ Beginner-friendly, type-safe API
- ğŸ”¹ Zero heavy ML dependencies



## ğŸ“¦ Installation

Add Neurocore to your project:

```bash
cargo add neuroflow
```

Or manually include it in `Cargo.toml`:

```toml
[dependencies]
neurocore = "0.1.0"
```



## ğŸ§  Example Usage

```rust
use neurocore::{Dense, Activation};

fn main() {
    // Create a Dense layer with 3 inputs and 2 outputs
    let layer = Dense::new(3, 2, Activation::Relu);

    // Example input vector
    let input = vec![1.0, 2.0, 3.0];

    // Perform forward propagation
    let output = layer.forward(&input);

    println!("Layer output: {:?}", output);
}
```



## ğŸ§© Architecture

Neurocore is built around three core components:

### âœ” 1. Activation Enum
Implements:
- ReLU  
- Sigmoid  
- Tanh  
- Linear  

Each with its own mathematical transformation.

### âœ” 2. Dense Layer
A fully connected layer with:
- Weight matrix  
- Bias vector  
- Activation function  
- Forward propagation logic  

### âœ” 3. Serialization
Neurocore includes automatic support for:

```rust
#[derive(Serialize, Deserialize)]
```

Allowing trained layers to be saved and loaded easily.



## âš¡ Performance

Neurocore is optimized for:
- minimal allocations  
- fast forward-pass execution  
- deterministic and stable results  
- tiny binary footprint  

The crate avoids any heavy machine-learning frameworks, making it ideal for embedded devices and performance-focused systems.


## ğŸ“š Roadmap

Planned major updates:
- Multi-layer neural network (`Sequential`)
- Convolutional layer support
- GPU acceleration (WGPU)
- Training engine (SGD, ADAM)
- Dataset loader module
- Dropout and regularization tools



## ğŸ‘‘ Author

**Created by:**  
### **Waithaka Njoroge(seleste)**  
Rust developer â€¢ Machine learning enthusiast â€¢ Systems engineer



## ğŸ“„ License

This project is licensed under the **MIT License**.



## â­ Support the Project

If you find Neurocore helpful, consider:
- â­ Starring the GitHub repository  
- ğŸ› ï¸ Contributing code  
- ğŸ’¡ Suggesting new features  

Your support helps grow this project into a full ML engine written in Rust.
